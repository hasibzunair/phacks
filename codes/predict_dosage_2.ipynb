{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "92dPh8qFyGcP",
    "outputId": "c3ea8661-0b58-4479-a692-caf5f7d41c77"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "psp =pd.read_excel('PSP_Data_V3.xlsx', header=1)\n",
    "#psp = pd.concat(pd.read_excel('PSP_Data_V3.xlsx', sheet_name=None, skiprows=1, index_col=False), ignore_index=False)\n",
    "#psp = pd.read_excel('PSP_Data_V3.xlsx', header=1,sheet_name=None, skiprows=1, index_col=False, \n",
    "#                 parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True, \n",
    "#                 low_memory=False, index_col='dt')\n",
    "psp.isnull().sum()\n",
    "\n",
    "############# cleaning data\n",
    "labels, levels = pd.factorize(psp.Dosage)\n",
    "psp.Dosage[psp.Dosage=='Unknown'].value_counts()\n",
    "np.unique(labels)\n",
    "psp.Dosage=labels\n",
    "\n",
    "labels, levels = pd.factorize(psp['Gender ID'])\n",
    "psp['Gender ID']=labels\n",
    "\n",
    "\n",
    "psp.loc[psp['Age Range']=='0-9','Age Range']=5\n",
    "psp.loc[psp['Age Range']=='10-19','Age Range']=15\n",
    "psp.loc[psp['Age Range']=='20-29','Age Range']=25\n",
    "psp.loc[psp['Age Range']=='30-39','Age Range']=35\n",
    "psp.loc[psp['Age Range']=='40-49','Age Range']=45\n",
    "psp.loc[psp['Age Range']=='50-59','Age Range']=55\n",
    "psp.loc[psp['Age Range']=='60-69','Age Range']=65\n",
    "psp.loc[psp['Age Range']=='70-79','Age Range']=75\n",
    "psp.loc[psp['Age Range']=='80-89','Age Range']=85\n",
    "psp.loc[psp['Age Range']=='90-99','Age Range']=95\n",
    "psp.loc[psp['Age Range']=='100-109','Age Range']=105\n",
    "psp.loc[psp['Age Range']=='110-119','Age Range']=115\n",
    "\n",
    "labels, levels = pd.factorize(psp['Diagnosis ID'])\n",
    "np.unique(labels)\n",
    "psp['Diagnosis ID']=labels\t\n",
    "\n",
    "labels, levels = pd.factorize(psp['Biologic Line of Therapy'])\n",
    "np.unique(labels)\n",
    "psp['Biologic Line of Therapy']=labels\t\n",
    "\n",
    "labels, levels = pd.factorize(psp['Patient Receiving Free Drug'])\n",
    "np.unique(labels)\n",
    "psp['Patient Receiving Free Drug']=labels\t\n",
    "\n",
    "labels, levels = pd.factorize(psp['Frequency'])\n",
    "np.unique(labels)\n",
    "psp['Frequency']=labels\t\n",
    "psp[psp['Frequency']==1]['Frequency'].value_counts()\n",
    "\n",
    "labels, levels = pd.factorize(psp['Status Group'])\n",
    "np.unique(labels)\n",
    "psp['Status Group']=labels\t\n",
    "\n",
    "labels, levels = pd.factorize(psp['Status'])\n",
    "np.unique(labels)\n",
    "psp['Status']=labels\t\n",
    "\n",
    "labels, levels = pd.factorize(psp['Status Description'])\n",
    "np.unique(labels)\n",
    "psp[psp['Status Description']=='Unknown']['Status Description'].value_counts()\n",
    "psp['Status Description']=labels\n",
    "#psp[(psp['Status Description']==2) & (psp['Frequency']==1) & (psp['Dosage']==1) & (psp['Biologic Line of Therapy']==6)]\n",
    "\n",
    "\n",
    "labels, levels = pd.factorize(psp['Case State'])\n",
    "np.unique(labels)\n",
    "psp[psp['Case State']=='Unknown']['Case State'].value_counts()\n",
    "psp['Case State']=labels\n",
    "\n",
    "psp.drop('Re-Engagement Day',axis=1,inplace=True)\n",
    "psp.drop('Re-Engagement On Drug Start Day',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#psp[psp['Diagnosis ID']==2]['Di']\n",
    "psp.loc[psp['Diagnosis ID']==9,'Diagnosis ID']=None\n",
    "psp.loc[psp['Biologic Line of Therapy']==6,'Biologic Line of Therapy']=None\n",
    "psp.loc[psp['Frequency']==1,'Frequency']=None\n",
    "psp.loc[psp['Dosage']==1,'Dosage']=None\n",
    "psp.loc[psp['Status Description']==2,'Status Description']=None\n",
    "#psp.drop('Status Description',axis=1,inplace=True)\n",
    "\n",
    "psp[psp['Diagnosis ID'].isnull()]\n",
    "psp[psp['Biologic Line of Therapy'].isnull()]\n",
    "\n",
    "psp.fillna(method='bfill',inplace=True)\n",
    "psp.fillna(method='ffill',inplace=True)\n",
    "\n",
    "############# fill with mean\n",
    "#psp.fillna(psp.mean(), inplace=True)\n",
    "\n",
    "psp.isnull().sum()\n",
    "\n",
    "X=psp.to_numpy()\n",
    "X=np.delete(X,5,1)\n",
    "Y=psp['Dosage'].to_numpy()\n",
    "\n",
    "\n",
    "##################### split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "############### Training\n",
    "\n",
    "from sklearn import metrics\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "# fit model no training data\n",
    "model = XGBClassifier(learning_rate=0.001,n_estimators=200,objective='rank:sofmax',max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "#plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "           #edgecolors='k')\n",
    "# Plot the testing points\n",
    "#ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    " #         edgecolors='k', alpha=0.6)\n",
    "\n",
    "\n",
    "############ Using keras\n",
    "from datetime import datetime\n",
    "dates = []\n",
    "\n",
    "for x in psp.index[0:len(psp.index)]:\n",
    "  dates.append(x[0])\n",
    "\n",
    "psp['month_year']=dates\n",
    "psp.drop('aa=',axis=1,inplace=True)\n",
    "psp.index[0:len(psp.index)][0]\n",
    "type(psp.month_year)\n",
    "psp['aa'] =  pd.to_datetime(psp.month_year, format='%m-%Y')\n",
    "time.strptime('01-2018', '%m-%Y')\n",
    "pd.DatetimeIndex(psp.index[1][0])\n",
    "import calendar\n",
    "import datetime\n",
    "psp['year'] = pd.DatetimeIndex(psp.index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "#    model.add(LSTM(70))\n",
    "#    model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=70, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "gQCPNk2qPZpc",
    "outputId": "7b1e8915-a237-49e3-eb6c-3288bb39d1db"
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "\n",
    "for x in psp.index[0:len(psp.index)]:\n",
    "  dates.append(x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "UUNIQOozJ-Rs",
    "outputId": "4ffda348-0621-4759-f47f-0b1a439d70c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "cm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalized=True, cmap='bone'):\n",
    "    plt.figure(figsize=[7, 7])\n",
    "    norm_cm = cm\n",
    "    if normalized:\n",
    "        norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(norm_cm, annot=cm, fmt='g', xticklabels=classes, yticklabels=classes, cmap=cmap)\n",
    "        plt.savefig('confusion-matrix.png')\n",
    "cm=cm.reshape(6,2)\n",
    "plot_confusion_matrix(cm, ['Dosage 1', 'Dosage 2', 'Dosage 3'])\n",
    "plot_confusion_matrix(cm, ['Dosage 1', 'Dosage 2'])\n",
    "\n",
    "\n",
    "classes=['Dosage 1', 'Dosage 2', 'Dosage 3']\n",
    "\n",
    "def pretty_print_conf_matrix(y_true, y_pred, \n",
    "                             classes,\n",
    "                             normalize=False,\n",
    "                             title='Confusion matrix',\n",
    "                             cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Mostly stolen from: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "    Normalization changed, classification_report stats added below plot\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Configure Confusion Matrix Plot Aesthetics (no text yet) \n",
    "    plt.figure(num=None, figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=18)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylabel('True label', fontsize=14)\n",
    "    plt.xlabel('Predicted label', fontsize=14)\n",
    "\n",
    "    # Calculate normalized values (so all cells sum to 1) if desired\n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(),2) #(axis=1)[:, np.newaxis]\n",
    "    print('\\n')\n",
    "    # Place Numbers as Text on Confusion Matrix Plot\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if i==0:\n",
    "          plt.text(j, i+0.4, cm[i, j],\n",
    "                   horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20)\n",
    "        elif i==1:\n",
    "          plt.text(j, i+0.2, cm[i, j],\n",
    "                   horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20)\n",
    "        else:\n",
    "          plt.text(j, i-0.2, cm[i, j],\n",
    "                   horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20)\n",
    "\n",
    "    # Add Precision, Recall, F-1 Score as Captions Below Plot\n",
    "    rpt = classification_report(y_true, y_pred)\n",
    "    rpt = rpt.replace('avg / total', '      avg')\n",
    "    rpt = rpt.replace('support', 'N Obs')\n",
    "\n",
    "    plt.annotate(rpt, \n",
    "                 xy = (0,0), \n",
    "                 xytext = (-120, -260), \n",
    "                 xycoords='axes fraction', textcoords='offset points',\n",
    "                 fontsize=20, ha='left')    \n",
    "\n",
    "    # Plot\n",
    "    plt.tight_layout()\n",
    "import itertools\n",
    "  \n",
    "pretty_print_conf_matrix(y_test, y_pred, \n",
    "                         classes= ['0', '1', '2'],\n",
    "                         normalize=False, \n",
    "                         title='Confusion Matrix')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "Sxj1DkU-_PdO",
    "outputId": "7e4fdf31-932c-41d9-edca-a128f565de31"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the psp data\n",
    "psp = pd.concat(pd.read_excel('PSP_Data_V3.xlsx', sheet_name=None, skiprows=1, index_col=False), ignore_index=False)\n",
    "print(psp.describe())\n",
    "\n",
    "\"\"\"Preprocessing the data\"\"\"\n",
    "# Define the training label and check for the class balance\n",
    "target_label = psp['Patient Receiving Free Drug'].unique()\n",
    "target_count = psp['Patient Receiving Free Drug'].value_counts()\n",
    "print('Patient not receiving free drug: ', target_count[0])\n",
    "print('Patient receiving free drug: ', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "#Set tick colors:\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', colors='red')\n",
    "ax.tick_params(axis='y', colors='red')\n",
    "target_count.plot(kind='bar', title='Total Number of target labels', color = 'b')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#\n",
    "# Put all the fraud class in a separate dataset.\n",
    "psp['Patient Receiving Free Drug'][psp['Patient Receiving Free Drug'] == \"Yes\"] = 1\n",
    "psp['Patient Receiving Free Drug'][psp['Patient Receiving Free Drug'] == \"No\"] = 0\n",
    "\n",
    "yes_df = psp.loc[psp['Patient Receiving Free Drug'] == 1]\n",
    "#Randomly select 37662 observations\n",
    "no_df = psp.loc[psp['Patient Receiving Free Drug'] == 0].sample(n=target_count[1],random_state=42)\n",
    "\n",
    "# Concatenate both dataframes again\n",
    "normalized_df = pd.concat([yes_df, no_df])\n",
    "\n",
    "#plot the dataset after the undersampling\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.countplot('Patient Receiving Free Drug', data=normalized_df)\n",
    "plt.title('Balanced Classes')\n",
    "plt.show()\n",
    "\n",
    "# Define the training label and check for the class balance\n",
    "target_label_1 = normalized_df['Patient Receiving Free Drug'].unique()\n",
    "target_count_1 = normalized_df['Patient Receiving Free Drug'].value_counts()\n",
    "print('Patient not receiving free drug : ', target_count_1[0])\n",
    "print('Patient receiving free drug : ', target_count_1[1])\n",
    "print('Proportion:', round(target_count_1[0] / target_count_1[1], 2), ': 1')\n",
    "\n",
    "\n",
    "# normalized_df= normalized_df.drop([\"Day Enrollment Received\", \"Day Enrollment Completed\", \"On Drug Start Day\", \"Last On Drug Day\", \"State Change Day\", \"Re-Engagement Day\", \"Re-Engagement On Drug Start Day\",\"Payment Method #1\", \"Payment Method #2\", \"Payment Method #3\", \"Payment Method #4\", \"Payment Method #5\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGZKFc0B0GUa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Competition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
